{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7 \n",
    "\n",
    "## Grade: /100 pts\n",
    "\n",
    "This notebook contains the questions for Assignment 7. \n",
    "\n",
    "Make sure to complete this assignment individually and appropriately reference all external code and documentation used. ***In order for your submission to be valid, you must adhere to the function definitions which have been made (failure to do so will result in a grade of 0). You must upload this completed Jupyter Notebook file as your submission (other file types are not permitted and will result in a grade of 0).*** You are responsible for selecting and importing additional packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "Feel free to add any libraries to the Preliminaries. However, be mindful of every question's restrictions as some may exclude use of some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T19:58:19.995708Z",
     "start_time": "2023-12-12T19:58:17.205432Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## perform the necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.metrics import recall_score, make_scorer, mean_squared_error, confusion_matrix, precision_score, roc_curve, auc, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "\n",
    "In this Assignment you need to download and use \"Dataset.csv\". \n",
    "\n",
    "This dataset is a modified dataset from Kaggle datasets called \"Lower Back Pain Symptoms Dataset\". Lower back pain can be caused by a variety of problems with any parts of the complex, interconnected network of spinal muscles, nerves, bones, discs or tendons in the lumbar spine.\n",
    "This data set is about to identify/label a person as abnormal or normal using collected physical spine details/data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Load Datasets (15pts)\n",
    "\n",
    "A) Load the \"Dataset.csv\" file.\n",
    "\n",
    "B) Encode the output classes `Label` (0: Normal, 1: Abnormal) and separate inputs and outputs (features and target). (2 pts)\n",
    "\n",
    "C) Split the data into equals-sized training and test sets. Use a random_state = 42, and ensure the `balanced distribution` of labels when splitting data.  \n",
    "\n",
    "D) How many observations do you have in your training set?  \n",
    "\n",
    "E) How many observations for each class in your training set?\n",
    "\n",
    "F) Z-standarize the input features of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T19:58:20.000740Z",
     "start_time": "2023-12-12T19:58:20.000282Z"
    }
   },
   "outputs": [],
   "source": [
    "### Q1A) \n",
    "# Read Data \n",
    "data = pd.read_csv('Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T19:58:20.001922Z",
     "start_time": "2023-12-12T19:58:20.001047Z"
    }
   },
   "outputs": [],
   "source": [
    "### Q1B) \n",
    "# Encode Output Class\n",
    "\n",
    "data['Label'] = data['Label'].astype('category')\n",
    "encode_map = {\n",
    "    'Abnormal': 1,\n",
    "    'Normal': 0\n",
    "}\n",
    "\n",
    "data['Label'].replace(encode_map, inplace=True)\n",
    "\n",
    "Xdata = data.drop('Label', axis=1)\n",
    "ydata = data['Label']\n",
    "\n",
    "### Q1C) \n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    Xdata, ydata, \n",
    "    test_size=0.5,       # 50% of the data will be used for testing\n",
    "    random_state=42,     # Ensures a reproducible split\n",
    "    stratify=ydata           # Preserve the class distribution in the split\n",
    ")\n",
    "\n",
    "### Q1D) \n",
    "print(Xtrain.shape)\n",
    "\n",
    "\n",
    "### Q1E) \n",
    "print(ytrain.value_counts())\n",
    "\n",
    "### Q1F) \n",
    "scaler = StandardScaler()\n",
    "XtrainScaled = scaler.fit_transform(Xtrain)\n",
    "XtestScaled = scaler.fit_transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Logistic Regression (15 pts)\n",
    "\n",
    "A) Build a L1-regularized logistic regression model to all the training data, and then get the predicted labels for each item of the test set. Tip: use the 'saga' solver for L1 regularization.\n",
    "\n",
    "B) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "C) Print out the model execution time (both training and test time) in milliseconds. Please keep two decimal places.\n",
    "\n",
    "D) Plot ROC curve and report the area under the ROC curve for the test data set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T19:58:20.001622Z"
    }
   },
   "outputs": [],
   "source": [
    "### Q2A) \n",
    "model = LogisticRegression(penalty = 'l1', solver='saga')\n",
    "\n",
    "time1 = time.time()\n",
    "#fit model \n",
    "model.fit(XtrainScaled,ytrain)\n",
    "time2 = time.time()\n",
    "#predict labels\n",
    "ypred = model.predict(XtestScaled)\n",
    "time3 = time.time()\n",
    "\n",
    "### Q2B) \n",
    "print('The Logistic Regression Precision is ', precision_score(ytest, ypred))\n",
    "print('The Logistic Regression Recall is ', recall_score(ytest, ypred))\n",
    "print('The Logistic Regression F1-score is ', f1_score(ytest, ypred))\n",
    "\n",
    "### Q2C) \n",
    "print('The Logistic Regression model training time is '+ str(round((time2-time1)*1000,2)) + ' ms')\n",
    "print('The Logistic Regression model test time is '+ str(round((time3-time2)*1000,2)) + ' ms')\n",
    "\n",
    "\n",
    "\n",
    "prob_estimates = model.predict_proba(XtestScaled)[:, 1]\n",
    "\n",
    "# Compute ROC AUC\n",
    "fpr, tpr, thresholds = roc_curve(ytest, prob_estimates)\n",
    "auc_roc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label=f'AUC - Logistic Regression = {auc_roc:.4f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print('The area under the ROC curve is', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question3: Neural Network \n",
    "\n",
    "\n",
    "### Q3a) Building model (15 pts)\n",
    "\n",
    "Build a simple neural network model (NN_model1) using PyTorch packages with the features in the data set as the input units and two output units for the two output classes:\n",
    "\n",
    "* Use a LogSigmoid as your output non-linearity.\n",
    "* Use the Cross-entropy loss as a training criterion. \n",
    "* Use Stochastic gradient descent optimizer with a learning rate of 0.01. \n",
    "* Run the optimization for 8000 iterations and record the loss for each iteration. \n",
    "* Plot the loss versus iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T19:58:20.004731Z",
     "start_time": "2023-12-12T19:58:20.003546Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define linear model \n",
    "class LinearModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_classes):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Neural Network Architecture\n",
    "        self.dense1 = torch.nn.Linear(in_features=num_features, out_features=num_classes)\n",
    "        self.activation = torch.nn.LogSigmoid()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.dense1(X)\n",
    "        X = self.activation(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T19:58:20.009815Z",
     "start_time": "2023-12-12T19:58:20.005527Z"
    }
   },
   "outputs": [],
   "source": [
    "NN_model1 = LinearModel(12,2)\n",
    "Xt = torch.FloatTensor(XtrainScaled)\n",
    "yt = torch.LongTensor(ytrain.values)\n",
    "y_pred = NN_model1.forward(Xt)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(NN_model1.parameters(), lr=1e-2)\n",
    "\n",
    "max_iter = 8000\n",
    "lossRecord = np.zeros(max_iter)\n",
    "time1 = time.time()\n",
    "for i in range(max_iter):\n",
    "    # Intialize the gradient \n",
    "    optimizer.zero_grad()\n",
    "    # Get current \n",
    "    y_pred = NN_model1.forward(Xt) # Get a forward pass with gradient \n",
    "    loss = criterion(input=y_pred, target=yt) # Caluculate the loss  \n",
    "    lossRecord[i]=loss\n",
    "    loss.backward() # propagate the derivative backwards \n",
    "    optimizer.step() # Take one updating step\n",
    "time2 = time.time()\n",
    "plt.plot(np.arange(max_iter),lossRecord)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cross entropy Loss')\n",
    "plt.title('Iteration vs Loss for NN_model1')\n",
    "\n",
    "\n",
    "print('The NN_model1 training time is '+ str(round((time2-time1)*1000,2)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3b) Prediction (20 pts)\n",
    "\n",
    "Now use your trained model (NN_model1) to make predictions on the test set.\n",
    "\n",
    "A) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "B) Print out the model execution time (both training and test time) in milliseconds. Please keep two decimal places.\n",
    "\n",
    "C) Plot ROC curve and report the area under the ROC curve for the test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T19:58:20.008447Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtt = torch.FloatTensor(XtestScaled)\n",
    "time1 = time.time()\n",
    "with torch.no_grad():\n",
    "    y_pred = NN_model1(Xtt)\n",
    "time2 = time.time()\n",
    "\n",
    "yp = y_pred.argmax(dim=1).numpy()  # Convert to class indices\n",
    "print('The NN_model1 Precision is ', precision_score(ytest, yp))\n",
    "print('The NN_model1 Recall is ', recall_score(ytest, yp))\n",
    "print('The NN_model1 F1-score is ', f1_score(ytest, yp))\n",
    "\n",
    "\n",
    "print('The NN_model1 test time is '+ str(round((time2-time1)*1000,2)) + ' ms')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "yprob = y_pred.numpy()[:, 1]  # Probabilities for the positive class    \n",
    "fpr, tpr, thresholds = roc_curve(ytest, yprob)\n",
    "auc_roc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label=f'AUC - NN_model1 = {auc_roc:.4f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print('The area under the ROC curve is', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3c) Adding hidden layers (15 pts)\n",
    "Change the neural network (NN_model2) and add two hidden layers with 100 and 60 units, respectively. Use the LogSigmoid non-linearity for the hidden layers. Leave all the other parameters the same as for Question 3a. Again train for 8000 iterations and plot the loss as a function of the iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T19:58:20.011456Z",
     "start_time": "2023-12-12T19:58:20.010800Z"
    }
   },
   "outputs": [],
   "source": [
    "class NonLinearModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_classes):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Neural Network Architecture: \n",
    "        self.dense1 = torch.nn.Linear(in_features=num_features, out_features=100)\n",
    "        self.activation1 = torch.nn.LogSigmoid()\n",
    "        self.dense2 = torch.nn.Linear(in_features=100, out_features=60)\n",
    "        self.activation2 = torch.nn.LogSigmoid()\n",
    "        self.dense3 = torch.nn.Linear(in_features=60, out_features=num_classes)\n",
    "        self.activation3 = torch.nn.LogSigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.dense1(X)  \n",
    "        X = self.activation1(X)\n",
    "        X = self.dense2(X)\n",
    "        X = self.activation2(X)\n",
    "        X = self.dense3(X)\n",
    "        X = self.activation3(X)\n",
    "        return X\n",
    "\n",
    "NN_model2 = NonLinearModel(12,2)\n",
    "y_pred = NN_model2.forward(Xt)\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(NN_model2.parameters(), lr=1e-2)\n",
    "\n",
    "max_iter = 8000\n",
    "lossRecord = np.zeros(max_iter)\n",
    "time1 = time.time()\n",
    "for i in range(max_iter):\n",
    "    # Intialize the gradient \n",
    "    optimizer.zero_grad()\n",
    "    # Get current \n",
    "    y_pred = NN_model2.forward(Xt) # Get a forward pass with gradient \n",
    "    loss = criterion(input=y_pred, target=yt) # Caluculate the loss  \n",
    "    lossRecord[i]=loss\n",
    "    loss.backward() # propagate the derivative backwards \n",
    "    optimizer.step() # Take one updating step\n",
    "time2 = time.time()\n",
    "plt.plot(np.arange(max_iter),lossRecord)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cross entropy Loss')\n",
    "plt.title('Iteration vs Loss for NN_model2')\n",
    "\n",
    "print('The NN_model2 training time is '+ str(round((time2-time1)*1000,2)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3d) Prediction and model selection (20 pts)\n",
    "Now use your trained model in Question 3c (NN_model2) to make predictions on the test set.\n",
    "\n",
    "A) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "B) Print out the model execution time (both training and test time) in milliseconds. Please keep two decimal places.\n",
    "\n",
    "C) Plot ROC curve and report the area under the ROC curve for the test data set. \n",
    "\n",
    "__Written answer:__ Compare this model (NN_model2) to the results from Question 2 (Logistic Regression) and 3b (NN_model1), what do you conclude? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T19:58:20.012470Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtt = torch.FloatTensor(XtestScaled)\n",
    "time1 = time.time()\n",
    "with torch.no_grad():\n",
    "    y_pred = NN_model2(Xtt)\n",
    "time2 = time.time()\n",
    "\n",
    "yp = y_pred.argmax(dim=1).numpy()  # Convert to class indices\n",
    "print('The NN_model2 Precision is ', precision_score(ytest, yp))\n",
    "print('The NN_model2 Recall is ', recall_score(ytest, yp))\n",
    "print('The NN_model2 F1-score is ', f1_score(ytest, yp))\n",
    "\n",
    " \n",
    "print('The NN_model2 test time is '+ str(round((time2-time1)*1000,2)) + ' ms')    \n",
    "\n",
    "\n",
    "yprob = y_pred.numpy()[:, 1]  # Probabilities for the positive class    \n",
    "fpr, tpr, thresholds = roc_curve(ytest, yprob)\n",
    "auc_roc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label=f'AUC - NN_model2 = {auc_roc:.4f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print('The area under the ROC curve is', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Written answer:__ Making the network deeper does not necessarily improve the performance but increases the execution time. However, we need to check their generalization performance to decide if depth and nonlinearity are required.\n",
    "Logistic regresssion will be the choice for this dataset and problem, especially if we have limited resources for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T19:58:20.013701Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
